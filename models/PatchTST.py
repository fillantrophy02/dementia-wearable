import math
import torch
import torch.nn as nn
import torchmetrics
from config import *
from pretrained_for_TL.wearable_korean.patchtst import WearableKoreanPatchTST
from transformers import PatchTSTConfig, PatchTSTModel

class PatchTST(nn.Module):
    '''Expect input of size (N, L, H_in) where N = batch_size, L = length of sequence, H_in = input_size aka no. of features'''
    def __init__(self):
        super().__init__()

        if is_transfer_learning:
            if transfer_learning_dataset == "etth":
                pass
            else:
                assert chosen_model == "PatchTST" and data_group == 'Korean-Fitbit Common Features', \
                    "Error: Currently, only PatchTST on common features has been implemented for transfer learning."
                
                if transfer_learning_dataset == "wearable_korean":
                    pretrained = WearableKoreanPatchTST()
                elif transfer_learning_dataset == "fitbit_mci":
                    pass

                self.reshape1 = nn.Linear(input_size, num_features)
                pretrained.load_state_dict(torch.load(f'pretrained_for_TL/{transfer_learning_dataset}/{chosen_model}.pth'))
                self.backbone = pretrained.backbone
                self.hidden1 = nn.Linear(num_features * hidden_size, hidden_size) # 10 is no. of common features
                    
        else:
            config = PatchTSTConfig(
                num_input_channels=input_size,
                context_length=no_of_days,
                patch_length=2,
                patch_stride=1,
                num_hidden_layers=num_layers,
                d_model=hidden_size,
                attention_dropout=dropout,
                ff_dropout=dropout,
                ffn_dim=ffn_dim,
                scaling=None,
                prediction_length=prediction_length,
                num_targets=input_size
            )
            self.backbone = PatchTSTModel(config).to(device)
            self.hidden1 = nn.Linear(input_size * hidden_size, 64)

        self.fc = nn.Linear(hidden_size, 1)
        self.dropout = nn.Dropout(dropout)
        self.activation = nn.ELU()
        self.sigmoid = nn.Sigmoid()
        self.loss = nn.BCELoss()

    def forward(self, x):
        outputs = self.backbone(
            past_values=x, # past mask & pos encoding will be auto generated by backbone
        )
        h = outputs.last_hidden_state # (N, input_size, num_patches, hidden_size)
        h = h.mean(dim=2) # (N, input_size, hidden_size)
        h = torch.flatten(h, 1) # (N, input_size * hidden_size)
        x = self.dropout(self.activation(self.hidden1(h)))
        x = self.sigmoid(self.fc(x))
        return x
    